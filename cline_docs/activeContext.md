# Active Context: Vinted Lens

## Current Focus
Re-enabling parallel processing with OpenAI GPT-4V

## Recent Changes
- Migrated from Claude to OpenAI GPT-4V
- Added JSON extraction from markdown responses
- Updated options page for OpenAI settings
- Added cost tracking and budget controls
- Added debug logging for API responses
- Fixed API key handling

## Next Steps
1. Re-enable Parallel Processing
   - Restore batch processing
   - Implement request queuing
   - Add rate limiting for OpenAI
   - Test concurrent requests
   - Handle rate limits properly

2. Optimize Performance
   - Fine-tune batch sizes
   - Optimize token usage
   - Cache common responses
   - Improve error recovery

3. Enhance Cost Management
   - Add detailed cost analytics
   - Implement smart budget controls
   - Add usage predictions
   - Optimize token efficiency

## Current Priorities
1. Performance improvement with parallel processing
2. Cost optimization and analytics
3. User feedback on performance

## Open Questions
- Optimal batch size for parallel requests
- Best practices for rate limit handling
- Most efficient prompt structure
- Cost prediction algorithms
